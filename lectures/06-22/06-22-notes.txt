[06/22/2023]

A process is a "running program" or "program in execution"

Processes have a variety of states:

   RUNNING           READY                 WAITING (on I/O)
    STATE            STATE                  STATE

   +-----+                              +-------------------------+
   |     |     +--------------------+   |                         |
   | CPU | <== | P3 | P6 | P5 | ... |   | I/O Subsystem           |
   | P22 |     +--------------------+   |                         |
   +-----+                              +-------------------------+

-- a CPU burst is a set of assembly/machine instructions that are
    executed by the CPU for a given process, e.g., P22

-- an I/O burst is one or more I/O operations for a given process

-- process states:

   RUNNING STATE: process is actually using the CPU,
                   i.e., executing its instructions

   READY STATE: process is ready to use the CPU,
                 i.e., process is idle in the ready queue

   WAITING STATE: process is waiting for I/O operation(s) to complete


-- CPU Scheduling (a.k.a. Short-Term Scheduling)

   The scheduling system enables one process to use the CPU
    while the other processes are waiting in the ready queue to use
     the CPU (or waiting in the I/O Subsystem)

   The goals of CPU Scheduling are to make efficient use of the CPU
    and to minimize the turnaround and wait times for each process

    -- we also want to achieve "fairness" across all processes


Multiprogramming
-- In multiprogramming, several processes reside in memory
    at the same time
-- CPU is shared and managed by the OS
-- Addresses the problem of the CPU being under-utilized
-- But this introduces a new problem...
   ...need to perform a "context switch" to switch the CPU's
       context from one process to another

Processes in a multiprogramming system COMPETE for the CPU,
 but they also often need to COOPERATE with one another via IPC


Program Execution (process)
---------------------------
   |
   |
   v
 CPU burst
   |
   |
   v
 I/O burst
   |
   |
   v
 CPU burst
   |
   |
   v
 I/O burst
   |
   |
   v
 CPU burst
   |
   |
   v
 I/O burst
   |
   |
   v
 CPU burst
   |
   |
   v
 I/O burst
   |
   |
   v
 CPU burst
   |
   v
---------------------------
process termination...



A CPU-bound process is one that will primarily have
 longer CPU bursts (spending most of its time either
  running with the CPU or waiting in the ready queue
   until the CPU becomes available)
...a.k.a. compute-bound process

An I/O-bound process is one that will primarily have
 shorter CPU bursts (spending most of its time waiting
  on I/O operations to complete)
...a.k.a. interactive process



   +---------+ blocked +--------------------------+  +---------------+
P1 |CPU burst|---------|       CPU burst          |--|   CPU burst   |--->
   +---------+ on I/O  +--------------------------+  +---------------+


   +-----+     blocked on I/O                      +-----+
P2 | CPU |-----------------------------------------| CPU |--------------->
   |burst|                                         |burst|
   +-----+                                         +-----+


    P1 is a CPU-bound or compute-bound process

    P2 is an I/O-bound or interactive process


    We can model this as follows:
    -- Consider CPU usage from a probabilistic viewpoint
    -- Suppose processes spend fraction p of their time
        waiting for I/O to complete

    -- Given n processes in memory
        (i.e., the degree or multiprogramming is n),
         then the probability that all n processes
          are waiting for I/O is:

              n
             p

                                     n
    -- CPU utilization is then: 1 - p



Preemption occurs when the currently running process is
 preempted (i.e., kicked out) while using the CPU

 -- might be because a newly arriving (more important)
     process has entered the ready state

 -- might be because of a timeout (i.e., time-sharing)


A non-preemptive algorithm implies that when a process
 is using the CPU, it will use the CPU as long as necessary
  to complete its CPU burst


Four scenarios:
(1) running process "decides" that it is done with its CPU burst
     (e.g., read() or waitpid() or etc.)

(2) running process "decides" to terminate

(3) running process is interrupted (goes back to the ready state/queue)

(4) preemption?  running process is not done with its current CPU burst...
    ...another process enters the ready state and might preempt



Prioritizing processes:
-- batch: no users are waiting
    (lower priority --- non-preemptive)

-- interactive: users are waiting for a (quick) response;
    also servers serving up files/webpages/etc.
     (higher priority --- preemptive)

-- real-time: preemption is not usually necessary
    because processes already are designed to "know"
     that they need to run quickly




CPU scheduling criteria and measures include:
-- CPU utilization (busy versus idle CPU time)
-- Throughput
-- Fairness
-- Arrival and departure rates
-- Response times (minimize variance of response times)
-- Wait times
-- Turnaround times


*** For each CPU burst per each process:

WAIT TIME: How much time does a process spend in the
           ready queue, waiting for time with the CPU?
           (Note that the process here is in the READY state.)

TURNAROUND TIME: How much time is required for a process to
           complete its CPU burst, from the time it first enters
           the ready queue (i.e., the READY state) through to
           when it completes its CPU burst?

TURNAROUND TIME  =  WAIT TIME  +  CPU BURST TIME  +  OVERHEAD
                                                    (context switches)


First-Come-First-Served (FCFS)     /* baseline algorithm */

  pid    CPU burst times
  P1       18 ms   <== CPU-bound process
  P2        3 ms   <== I/O-bound process
  P3        4 ms   <== I/O-bound process

  ready queue: P1 P2 P3

 (assume that all three processes arrived at time 0...)

   context switch       context switches
       v                  v   v    v      v
       +------------------+---+----+------+--------->
 FCFS: | P1               |P2 | P3 | idle | .......
       +------------------+---+----+------+--------->
    t: 0                  18  21   25

    P1 has 0 wait time         P1 has 18 ms turnaround time
    P2 has 18 ms wait time     P2 has 21 ms turnaround time
    P3 has 21 ms wait time     P3 has 25 ms turnaround time

-- When a process arrives or transitions to the ready state,
    we simply add it to the end of the READY queue

advantages: very simple; easy to implement; very low overhead

disadvantages: processes with larger CPU burst times will
                cause longer delays for other processes
                 (e.g., CPU-bound versus I/O-bound process mix)


Shortest Job First (SJF)

  pid    CPU burst times
  P1       18 ms   <== CPU-bound process
  P2        3 ms   <== I/O-bound process
  P3        4 ms   <== I/O-bound process

  ready queue: P2 P3 P1

 (assume that all three processes arrived at time 0...)

    context switches         context switch
      v   v    v                  v
      +---+----+------------------+-------------->
 SJF: |P2 | P3 | P1               | ............
      +---+----+------------------+-------------->
   t: 0   3    7                  25

    P1 has 7 ms wait time      P1 has 25 ms turnaround time
    P2 has 0 ms wait time      P2 has 3 ms turnaround time
    P3 has 3 ms wait time      P3 has 7 ms turnaround time

advantages: lower average wait/turnaround times (versus FCFS)

            good low turnaround times (and therefore low response times)
             for interactive or I/O-bound processes

disadvantages: processes with larger CPU burst times might end up
                facing INDEFINITE BLOCKING (or STARVATION)

               increased overhead due to the priority queue (log time)

               we have no way of knowing ahead of time exactly
                what CPU burst times will be for each process
                 (we can only predict these CPU burst times...)

STARVATION: a process faces starvation if we know that the
             process will NEVER complete its CPU burst

INDEFINITE BLOCKING: a process faces indefinite blocking if
  (or POSTPONEMENT)   the time to complete its CPU burst is
                       (likely) comparatively long...



Both FCFS and SJF are non-preemptive algorithms
-- once a process starts using the CPU for its CPU burst,
    it will continue UNINTERRUPTED until the burst is complete

What if we added preemption to SJF?
-- when process B arrives on the ready queue, it can potentially
    PREEMPT and replace the currently running process A
     iff B's CPU burst time is less than the
      remaining CPU burst time for process A
      ^^^^^^^^^


Shortest Remaining Time (SRT)   <== SJF with preemption

  pid    CPU burst times      arrival times
  P1       18 ms                  0 ms
  P2        3 ms                  2 ms
  P3        4 ms                  3 ms
  P4        3 ms                  5 ms

  ready queue (at time 0): P1 (removed from the queue and runs with the CPU)

  ready queue (at time 2): P1 (after the preemption)

  ready queue (at time 3): P3 P1 (we insert P3 at the front of the queue)

    context switches.......        context switch
      v  v   v   v    v                v
      +--+---+---+----+----------------+------------->
 SRT: |P1|P2 |P4 | P3 | P1             | ...........
      +--p---+---+----+----------------+------------->
   t: 0  2   5   8    12               28

  TO DO: calculate wait and turnaround times for each CPU burst...


advantages: lower average wait/turnaround times (versus FCFS);
             SRT is "better" at getting I/O-bound or interactive
              processes through the CPU even more quickly than SJF

            good low turnaround times (and therefore low response times)
             for interactive or I/O-bound processes

disadvantages: processes with larger CPU burst times might end up
                facing INDEFINITE BLOCKING (or STARVATION)

               increased overhead due to the priority queue (log time)

               we have no way of knowing ahead of time exactly
                what CPU burst times will be for each process
                 (we can only predict these CPU burst times...)

               more context switches are likely (versus SJF)






Priority scheduling algorithms

-- Each process is assigned a priority based on:
   -- predicted CPU burst times (e.g., SJF/SRT)
   -- ratio of CPU to I/O activity (predicted or expected)
   -- system resource usage
   -- arbitrary or hard-coded (user-defined?)

-- The process with the highest priority gets scheduled
    with the CPU first

-- When multiple processes have the same priority, we need
    a tie-breaker, which is a secondary algorithm on that
     subset (e.g., just use FCFS)

-- We decide (ahead of time) whether the algorithm is
    preemptive (e.g., SRT) or non-preemptive (e.g., SJF)

-- To help avoid starvation or indefinite blocking,
    we can use AGING: if a given process is in the READY state
     (i.e., in the ready queue) for some X amount of time,
      then we increase the priority of that process by Y

-- As a process is running with the CPU, change (lower?) its priority





ALGORITHM   PREEMPTION?     ADVANTAGE(S)           DISADVANTAGE(S)

 FCFS       non-preemptive  easy to implement      long wait times
                            minimal overhead       long turnaround times
                            no starvation

 SJF        non-preemptive  optimal (fastest)      starvation
                             (least average        requires us to predict
                               wait time)            CPU burst times

 SRT        preemptive                             starvation
                                                   requires us to predict
                                                     CPU burst times

 Priority   non-preemptive  finer control over     starvation
             or preemptive    process order        (also increased overhead)

 Priority   non-preemptive  no starvation          but we still have
  w Aging    or preemptive                          long wait times for
   (PWA)                                             low-priority processes




For SJF/SRT, we can predict the CPU burst times for
 each process based on historical data, e.g., measures
  of previous actual CPU burst times

Let's use EXPONENTIAL AVERAGING (for EACH process):

  alpha - constant in the range [0.0,1.0], often at least 0.5 or higher

  tau   - estimated CPU burst time

  t     - actual CPU burst time

We apply the formula below separately to each process...
 ...so we keep track of a tau value PER PROCESS

  tau     =  alpha  x  t    +   (1-alpha)  x  tau
     i+1                i                        i

   e.g., with alpha set to 0.5


   tau  = 10   <== initial guess -- could be random, hard-coded,
      0                a running average of the N previous actual
                        CPU burst times across all processes, etc.

   t  = 6      <== actual (first) CPU burst time
    0

   tau  =  0.5 x t  +  0.5 x tau   =  0.5 x 6  +  0.5 x 10  =  8 (next guess)
      1           0             0


   t  = 4      <== actual (second) CPU burst time
    1

   tau  =  0.5 x t  +  0.5 x tau   =  0.5 x 4  +  0.5 x 8   =  6 (next guess)
      2           1             1


   TO DO: calculate tau  etc. --- also re-calculate using different alpha values
                       3



Round Robin (RR) Algorithm

-- Essentially FCFS with a fixed time limit on each CPU burst
   -- i.e., a timeslice or a time quantum
              ^^^^^^^^^

-- When a process starts using the CPU for its current CPU burst,
    a timer is set

   -- The process either finishes its CPU burst before the
       timer (timeslice) expires

   -- Or...the process is PREEMPTED by the expiration of this timer,
       in which case the process is added back to the end of the ready queue
                                                      ^^^

-- Selection of the timeslice is crucial

   -- too large of a timeslice and we end up with FCFS

   -- too small of a timeslice and we have way too many context switches

   -- aim is to minimize turnaround times if we can get "most" of the
       processes finishing their respective CPU burst times
        within ONE timeslice

   -- heuristic is ~80% of CPU burst times should be less than the timeslice




                                        1
-- With N processes, each process gets ---th of CPU time
                                        N
    (which should ensure FAIRNESS)




-- If a process arrives at some later time (i.e., not all
    processes start at time 0), we need to decide where the
     process should be placed in the ready queue

   -- By default, we always place an arriving process at the
       end of the ready queue

   -- Alternate approach: when a process arrives, add it to
       the front of the queue (i.e., have it cut the line)

       -- this "breaks" the FAIRNESS idea

       -- the advantage here is that I/O-bound or interactive
           processes get through their CPU bursts quickly and
            get back to more I/O

       -- one other idea: maybe we only have certain processes
           that we've identified as I/O-bound cutting the line



e.g., apply the RR algorithm to the processes listed below...
       ...using a timeslice of 3ms


  pid   CPU burst time      arrival times
  P1      20 ms                 0 ms  <== the tie-breaker is pid order
  P2       5 ms                 0 ms
  P3       2 ms                 2 ms
  P4      10 ms                 4 ms

  Ready queue (at time 4): P3 P1 P4

   RR (with a timeslice of 3ms)
    |
 P1 >XXXp    XXXp    XXXp  XXXp  XXXpXXXXX.
 P2 >   XXXp       XX.
 P3 | >    XX.
 P4 |   >       XXXp    XXXp  XXXp  X.
    +------------------------------------------------> time
              111111111122222222223333333333
    0123456789012345678901234567890123456789

  LEGEND:
    > == process arrival time
    X == 1 ms of CPU burst time
    p == preemption (based on timeslice expiration)
    . == CPU burst completed

  TO DO: calculate wait and turnaround times for each CPU burst
          for each process

  TO DO: repeat the above analysis using different timeslices,
          e.g., 2ms, 1ms, 6ms, 20ms, etc. --- how might you
           determine what the "optimal" timeslice is...?

  TO DO: simulate FCFS, SJF, SRT for the process data above







ALGORITHM   PREEMPTION?     ADVANTAGE(S)           DISADVANTAGE(S)

 FCFS       non-preemptive  easy to implement      long wait times
                            minimal overhead       long turnaround times
                            no starvation

 SJF        non-preemptive  optimal (fastest)      starvation
                             (least average        requires us to predict
                               wait time)            CPU burst times

 SRT        preemptive                             starvation
                                                   requires us to predict
                                                     CPU burst times

 Priority   non-preemptive  finer control over     starvation
             or preemptive    process order        (also increased overhead)

 Priority   non-preemptive  no starvation          but we still have
  w Aging    or preemptive                          long wait times for
   (PWA)                                             low-priority processes

 RR         preemptive      favors both CPU-bound  overhead...!
                             and I/O-bound
                              processes?

                            no starvation
